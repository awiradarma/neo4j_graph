{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c375cae-0c38-4b4f-9b8d-c6cd50671472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "\n",
    "# Start neo4j using docker with apoc enabled\n",
    "# docker run --restart always --publish=7474:7474 --publish=7687:7687  -e NEO4J_apoc_export_file_enabled=true  -e NEO4J_apoc_import_file_enabled=true -e NEO4J_apoc_import_file_use__neo4j__config=true -e NEO4J_PLUGINS=\\[\\\"apoc\\\"\\] neo4j\n",
    "# then login to neo4j console and change the neo4j password from neo4j to password\n",
    "\n",
    "os.environ[\"NEO4J_URI\"] = \"bolt://localhost:7687\"\n",
    "os.environ[\"NEO4J_USERNAME\"] = \"neo4j\"\n",
    "os.environ[\"NEO4J_PASSWORD\"] = \"password\"\n",
    "\n",
    "graph = Neo4jGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "408ceb26-3625-4540-b9ac-1b44b931a87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# run llama3.1 using ollama run llama3.1\n",
    "\n",
    "#llm = ChatOpenAI(temperature=0, model_name=\"llama3.1\", base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.1\",\n",
    "    temperature=0,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "llm_transformer = LLMGraphTransformer(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d554a911-0525-4c97-9a66-691d7c6d882b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes:[Node(id='Marie Curie', type='Person', properties={}), Node(id='Pierre Curie', type='Person', properties={}), Node(id='University Of Paris', type='Organization', properties={})]\n",
      "Relationships:[]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "text = \"\"\"\n",
    "Marie Curie, born in 1867, was a Polish and naturalised-French physicist and chemist who conducted pioneering research on radioactivity.\n",
    "She was the first woman to win a Nobel Prize, the first person to win a Nobel Prize twice, and the only person to win a Nobel Prize in two scientific fields.\n",
    "Her husband, Pierre Curie, was a co-winner of her first Nobel Prize, making them the first-ever married couple to win the Nobel Prize and launching the Curie family legacy of five Nobel Prizes.\n",
    "She was, in 1906, the first woman to become a professor at the University of Paris.\n",
    "\"\"\"\n",
    "documents = [Document(page_content=text)]\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(documents)\n",
    "print(f\"Nodes:{graph_documents[0].nodes}\")\n",
    "print(f\"Relationships:{graph_documents[0].relationships}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5544510-760c-43fa-b65b-17efb4e97949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes:[Node(id='Marie Curie', type='Person', properties={}), Node(id='Pierre Curie', type='Person', properties={}), Node(id='University Of Paris', type='Organization', properties={})]\n",
      "Relationships:[]\n"
     ]
    }
   ],
   "source": [
    "llm_transformer_filtered = LLMGraphTransformer(\n",
    "    llm=llm,\n",
    "    allowed_nodes=[\"Person\", \"Country\", \"Organization\"],\n",
    "    allowed_relationships=[\"NATIONALITY\", \"LOCATED_IN\", \"WORKED_AT\", \"SPOUSE\"],\n",
    ")\n",
    "graph_documents_filtered = llm_transformer_filtered.convert_to_graph_documents(\n",
    "    documents\n",
    ")\n",
    "print(f\"Nodes:{graph_documents_filtered[0].nodes}\")\n",
    "print(f\"Relationships:{graph_documents_filtered[0].relationships}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9212b588-4623-4749-ac85-cfcb18dcd46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes:[Node(id='Marie Curie', type='Person', properties={}), Node(id='Pierre Curie', type='Person', properties={}), Node(id='University Of Paris', type='Organization', properties={})]\n",
      "Relationships:[]\n"
     ]
    }
   ],
   "source": [
    "llm_transformer_props = LLMGraphTransformer(\n",
    "    llm=llm,\n",
    "    allowed_nodes=[\"Person\", \"Country\", \"Organization\"],\n",
    "    allowed_relationships=[\"NATIONALITY\", \"LOCATED_IN\", \"WORKED_AT\", \"SPOUSE\"],\n",
    "    node_properties=[\"born_year\"],\n",
    ")\n",
    "graph_documents_props = llm_transformer_props.convert_to_graph_documents(documents)\n",
    "print(f\"Nodes:{graph_documents_props[0].nodes}\")\n",
    "print(f\"Relationships:{graph_documents_props[0].relationships}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e1556f7-c1ad-4810-a0dc-04d565db083a",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_graph_documents(graph_documents_props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cebd8be0-06d9-488c-bdbc-4062426f59f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Je suis fan de programmation Ã©galement ! (I'm a fan of programming too!) \\n\\nWould you like me to translate anything else?\", additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2024-09-14T02:03:59.809876226Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 858631697, 'load_duration': 10796080, 'prompt_eval_count': 30, 'prompt_eval_duration': 328894000, 'eval_count': 28, 'eval_duration': 357892000}, id='run-0ae97589-1a0b-456d-9207-f7138a46fa6b-0', usage_metadata={'input_tokens': 30, 'output_tokens': 28, 'total_tokens': 58})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that translates {input_language} to {output_language}.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"input_language\": \"English\",\n",
    "        \"output_language\": \"French\",\n",
    "        \"input\": \"I love programming.\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3378c816-07f7-4ec9-9afa-8453073241e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
